---
layout: page
title: Natural Language Processing
description: Resources for starting to learn NLP
img: 
importance: 1
---
These are resources for a variety of topics within Natural Language Processing (NLP). Many of these were created when I was learning about NLP or were created for the intro to NLP DiRP (Directed Reading Program) I am leading. I am by no means an expert on these topics, just a student wanting to share her knowledge. Please let me know if you see any mistakes here! 

<!-- <div class="h3">
    DiRP - Directed Reading Program
</div> -->

<div id="faq" role="tablist" aria-multiselectable="true">

<div class="card">
<div class="card-header" role="tab" id="intro">
<h5 class="card-title">
<a data-toggle="collapse" data-parent="#faq" href="#introcontent" aria-expanded="false" aria-controls="introcontent">
Introduction to NLP
</a>
</h5>
</div>
<div id="introcontent" class="collapse" role="tabcard" aria-labelledby="intro">
<div class="card-body">

- What is it?

- What kind of tasks exist?

- Where is the field now?

</div>
</div>
</div>

<div class="card">
<div class="card-header" role="tab" id="lr">
<h5 class="card-title">
<a class="collapsed" data-toggle="collapse" data-parent="#faq" href="#lrcontent" aria-expanded="false" aria-controls="lrcontent">
Linear Classification and Regression
</a>
</h5>
</div>
<div id="lrcontent" class="collapse in" role="tabcard" aria-labelledby="lr">
<div class="card-body">

<img class="img-fluid rounded z-depth-1" src="{{ site.baseurl }}/assets/img/classification1.jpg">
<img class="img-fluid rounded z-depth-1" src="{{ site.baseurl }}/assets/img/classification2.jpg">
<img class="img-fluid rounded z-depth-1" src="{{ site.baseurl }}/assets/img/classification3.jpg">
<img class="img-fluid rounded z-depth-1" src="{{ site.baseurl }}/assets/img/classification4.jpg">

</div>
</div>
</div>

<div class="card">
<div class="card-header" role="tab" id="sentiment">
<h5 class="card-title">
<a data-toggle="collapse" data-parent="#faq" href="#sentimentcontent" aria-expanded="false" aria-controls="sentimentcontent">
Sentiment Analysis
</a>
</h5>
</div>
<div id="sentimentcontent" class="collapse" role="tabcard" aria-labelledby="sentiment">
<div class="card-body">


</div>
</div>
</div>

<div class="card">
<div class="card-header" role="tab" id="transformer">
<h5 class="card-title">
<a class="collapsed" data-toggle="collapse" data-parent="#faq" href="#transformercontent" aria-expanded="false" aria-controls="transformercontent">
Transformers
</a>
</h5>
</div>
<div id="transformercontent" class="collapse" role="tabcard" aria-labelledby="transformer">
<div class="card-body">
Transformers are the building blocks for the language models we see today. They are built on the concept of attention and consist of encoder and decoder stacks. Attention allows for models to remember the context that a word was found in. I would recommend learning about this concept before learning about BERT and other language models. The notes below come from <a href="http://jalammar.github.io/illustrated-transformer/">The Illustrated Transformer</a>. These notes are better used as a supplement to the blog post than a replacement.
<img class="img-fluid rounded z-depth-1" src="{{ site.baseurl }}/assets/img/transformer1.jpg">
<img class="img-fluid rounded z-depth-1" src="{{ site.baseurl }}/assets/img/transformer2.jpg">
<img class="img-fluid rounded z-depth-1" src="{{ site.baseurl }}/assets/img/transformer3.jpg">

Alammar, Jay (2018). The Illustrated Transformer [Blog post]. Retrieved from https://jalammar.github.io/illustrated-transformer/
</div>
</div>
</div>

<div class="card">
<div class="card-header" role="tab" id="bert">
<h5 class="card-title">
<a data-toggle="collapse" data-parent="#faq" href="#bertcontent" aria-expanded="false" aria-controls="bertcontent">
BERT
</a>
</h5>
</div>
<div id="bertcontent" class="collapse" role="tabcard" aria-labelledby="bert">
<div class="card-body">
Large language models like BERT and GPT have taken over the field of NLP and are seen on many of the state of the art models for a variety of tasks. These language models are trained on HUGE amounts of data at large companies (Google and OpenAI). 
Below, I've attached my notes from reading <a href="http://jalammar.github.io/illustrated-bert/">The Illustrated BERT</a>. I would recommend reading his blog post and use these notes as a supplement since he explains the math behind this model much better than my notes can.
<img class="img-fluid rounded z-depth-1" src="{{ site.baseurl }}/assets/img/bert1.jpg">
<img class="img-fluid rounded z-depth-1" src="{{ site.baseurl }}/assets/img/bert2.jpg">
<img class="img-fluid rounded z-depth-1" src="{{ site.baseurl }}/assets/img/bert3.jpg">
<img class="img-fluid rounded z-depth-1" src="{{ site.baseurl }}/assets/img/bert4.jpg">

Alammar, Jay (2018). The Illustrated BERT [Blog post]. Retrieved from http://jalammar.github.io/illustrated-bert/
</div>
</div>
</div>

<div class="card">
<div class="card-header" role="tab" id="ethics">
<h5 class="card-title">
<a class="collapsed" data-toggle="collapse" data-parent="#faq" href="#ethicscontent" aria-expanded="false" aria-controls="ethicscontent">
Ethics
</a>
</h5>
</div>
<div id="ethicscontent" class="collapse in" role="tabcard" aria-labelledby="ethics">
<div class="card-body">
As the influence of technology in our world continues to grow, the need for ethical considerations for how that technology is used also grows.  
</div>
</div>
</div>

</div>